# --- Backend Configuration ---
# Your Weaviate Cluster URL (e.g. https://mesh-memory-xxxx.weaviate.network)
# Leave as "localhost" for local Docker setup
WEAVIATE_URL=localhost
WEAVIATE_PORT=8080

# Your Weaviate API Key (Required for Cloud, ignore for local)
WEAVIATE_API_KEY=

# Google Gemini API Key (Required for Multimodal Ingestion & Cloud Chat)
# Get one here: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=

# Groq API Key (Optional - Recommended for super fast chat)
# Get one here: https://console.groq.com/keys
GROQ_API_KEY=

# Ollama Model (Default: llama3)
OLLAMA_MODEL=llama3

# --- Frontend Configuration (for ui/.env.local) ---
# The URL of your backend. 
# For local dev: http://127.0.0.1:8000
# For production: https://your-backend.onrender.com
NEXT_PUBLIC_API_URL=http://127.0.0.1:8000
