# --- Backend Configuration ---
# Your Weaviate Cluster URL (e.g. https://mesh-memory-xxxx.weaviate.network)
# Leave as "localhost" for local Docker setup
WEAVIATE_URL=localhost
WEAVIATE_PORT=8080

# Explicitly set mode: "local" or "cloud". 
# If not set, it will be inferred from the URL (localhost = local, anything else = cloud).
WEAVIATE_MODE=local

# Your Weaviate API Key (Required for Cloud, ignore for local)
WEAVIATE_API_KEY=

# Google Gemini API Key (Required for Multimodal Ingestion & Cloud Chat)
# Get one here: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=

# Groq API Key (Optional - Recommended for super fast chat)
# Get one here: https://console.groq.com/keys
GROQ_API_KEY=

# Ollama Model (Default: llama3)
OLLAMA_MODEL=llama3

# --- Frontend Configuration (for ui/.env.local) ---
# The URL of your backend. 
# For local dev: http://127.0.0.1:8000
# For production: https://your-backend.onrender.com
NEXT_PUBLIC_API_URL=http://127.0.0.1:8000

# Read-Only Mode (For public demos like deployment)
# Set to "true" to disable ingestion/editing for visitors.
# Leave empty or "false" for your personal local instance.
NEXT_PUBLIC_READ_ONLY=false
