# MeshMemory Demo Recording Script ðŸŽ¥

**Goal:** Showcase MeshMemory as a "Living Second Brain" that runs locally but is powerful enough to be your primary knowledge engine.
**Duration:** ~2-3 Minutes (Short & Punchy)
**Resolution:** 1080p or 4K (Clean desktop, no clutter)

---

## ðŸŽ¬ Scene 1: The "Hook" (0:00 - 0:20)
*   **Visual:** Start on the **Dashboard** (Graph View). It should be moving slightly (physics enabled).
*   **Action:** Hover over a few nodes. Show connections lighting up.
*   **Voiceover / Caption:** "This isn't just a note-taking app. This is MeshMemory â€“ my local AI second brain. It doesn't just store data; it *understands* it."

## ðŸŽ¬ Scene 2: Multi-Modal Ingestion (0:20 - 1:00)
*   **Visual:** Zoom into the **"Neural Input"** panel on the left.
*   **Action 1 (Web):** Switch to the `WEB` tab. Paste a URL (e.g., a documentation page or technical article). Click "Ingest". Show the spinner.
*   **Action 2 (YouTube):** Switch to the `YOUTUBE` tab. Paste a video link (e.g., "Next.js 15 Tutorial"). Click "Ingest".
*   **Voiceover:** "I can throw anything at it. Websites, PDFs, or even YouTube videos. MeshMemory scrapes, chunks, and embeds it all automatically using local LLMs."

## ðŸŽ¬ Scene 3: The Graph Update (1:00 - 1:30)
*   **Visual:** Back to the **Graph**.
*   **Action:** Refresh or let it auto-update. Show the *new* nodes appearing.
*   **Action:** Click the new YouTube node. Show that it auto-fetched the *correct title* (thanks to our recent fix!).
*   **Voiceover:** "See that? The graph just evolved. It found connections between the video I just added and my existing React notes. No manual linking required."

## ðŸŽ¬ Scene 4: Neural Chat (RAG) (1:30 - 2:15)
*   **Visual:** Navigate to the **Chat** page.
*   **Action:** Type a query like: *"What are the key features of Next.js 15 based on the video I just watched?"*
*   **Action:** Show the AI generating the answer *and* citing the "YouTube Video" source at the bottom.
*   **Voiceover:** "Then I can just ask my brain. It uses RAG to pull the exact context and answer me perfectly. 100% private. 100% local."

## ðŸŽ¬ Scene 5: MCP & Closing (2:15 - 3:00)
*   **Visual:** Go to the **/demo** page or **How It Works**. Scroll down to the MCP card.
*   **Action:** Briefly show the MCP config json.
*   **Voiceover:** "And yes, it speaks MCP. I can plug this entire brain directly into Claude Desktop using the Model Context Protocol."
*   **Outro:** "I've deployed a read-only version for you to play with. Check the link below. Star the repo if you dig it!"

---

## ðŸ’¡ Pro Tips for Recording
1.  **Hide Bookmarks:** Clean up your browser bar.
2.  **Dark Mode:** Ensure system is in dark mode to match the app.
3.  **Mouse Movement:** Move smoothly. Don't jerk the mouse around.
4.  **Audio:** If recording voice, use a good mic. If not, use upbeat Lo-Fi background music.
